<!-- 
    based off of tutorials by Mike Mulshine et al
    dependencies are in https://ccrma.stanford.edu/~cc/220a/webchuck220aStereoRecorder/
-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<!--- make responsive for mobile devices -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
<!--- Include the ACE editor and webchuck stuff -->
  <link rel="stylesheet" href="https://ccrma.stanford.edu/~cc/220a/webchuck220aStereoRecorder/css/editor.css">
  <script type="text/javascript" src="https://ccrma.stanford.edu/~cc/220a/webchuck220aStereoRecorder/js/ace.js" charset="utf-8"></script>
  <script type="text/javascript" src="https://ccrma.stanford.edu/~cc/220a/webchuck220aStereoRecorder/js/editor.js"></script>
  <script type="text/javascript" src="https://ccrma.stanford.edu/~cc/220a/webchuck220aStereoRecorder/js/defer.js"></script>
  <script type="text/javascript" src="https://ccrma.stanford.edu/~cc/220a/webchuck220aStereoRecorder/js/webchuck_host_recorder.js"></script>

</head>

<p>Homework 4 - radio play
</p>
<h2>Spatialization comparisons, use headphones or ear buds</h2>
<p>Four soundfiles need to be preloaded -- mono.wav, stereo.wav, binaural.wav, spatializer.wav -- the first three were recorded with different kinds of mics and the last was created by feeding a mono file into the <a href="https://ccrma.github.io/music220a/07-time-and-space/ambisonic-recorder/">Ambisonic Spatializer</a> and capturing the result of moving it manually.
</p>
<pre><div id="editor2" class="ace_editor ace_hidpi ace-chuck">
// for something more dramatic in the live code, add more clips and reduce their spacing
for (0 => int i; i < names.size()*2; i++) { // play through the set of sound files twice
  spork ~clip(names[i % names.size()]);  // need to use % so the set of names repeats
  1::second => now;
}
</div></pre>
//////////////////////////////////////////////////// <br>
live code
<pre><div id="editor1" class="ace_editor ace_hidpi ace-chuck"> 
["mono.wav", "stereo.wav", "binaural.wav", "spatializer.wav"] @=> string names[];
fun void clip(string name)         // define "clip" as a function
{
  SndBuf2 mySnd => dac;            // wire up a sound file reader and connect to the DAC
  mySnd.read(name);                // specify the file name
  mySnd.length() => dur myDur;     // get the duration
<<< name, "is playing at", now/second, "for", myDur/second,"seconds">>>;
  myDur => now; 		   // quit this shred after sound file's duration has passed
}
for (0 => int i; i < names.size(); i++) {
  spork ~clip(names[i]); // play each file once in a sequence of calls to clip
  4::second => now;
}
while (true) 1::samp => now; // chuck forever, "stop" button finishes the recording and quits 
</div></pre>

<p>
<input id="startButton" type="button" value="Start" /> 
<input id="startButtonWithInput" type="button" value="ADC & Start" /> 
<input id="stopButton" type="button" value="Stop" /><br/><br/>
<input id="recordButton" type="button" value="Start Recording" /><br/><br/>
</p>
<div class="pure-u-3-4" id="audio-download-link">
output is a stereo .wav file

<script>
    var preloaded = false;
    var serverFilesToPreload = [
        {
            serverFilename: 'https://ccrma.stanford.edu/courses/220a/examples/webchuck/radio-play/wav/mono.wav',
            virtualFilename: 'mono.wav'
        },
        {
            serverFilename: 'https://ccrma.stanford.edu/courses/220a/examples/webchuck/radio-play/wav/stereo.wav',
            virtualFilename: 'stereo.wav'
        },
        {
            serverFilename: 'https://ccrma.stanford.edu/courses/220a/examples/webchuck/radio-play/wav/binaural.wav',
            virtualFilename: 'binaural.wav'
        },
        {
            serverFilename: 'https://ccrma.stanford.edu/courses/220a/examples/webchuck/radio-play/wav/spatializer.wav',
            virtualFilename: 'spatializer.wav'
        }
    ];
    var adc = null;
    const constraints = {'video': false, 'audio': {
        'echoCancellation': false,
        'autoGainControl': false,
        'noiseSuppression': false,
    }};
    var connectAudioInput = function() {
      navigator.mediaDevices.getUserMedia(constraints)
        .then( function( stream ) {
          adc = audioContext.createMediaStreamSource( stream );
          adc.connect( theChuck );
        });
    }
    var disconnectAudioInput = function() {
      if (adc != null) adc.disconnect( theChuck );
    }
    async function prep(withInput) {
        if (!preloaded) {
          await preloadFilenames( serverFilesToPreload );
        }
        await startChuck();
        await theChuckReady;
        theChuck.removeLastCode();
        if (!preloaded) {
//          await theChuck.runFile("isoRhythm.ck");
          preloaded = true;
        }
        if (withInput) connectAudioInput();
    }

var editor1 = newChuckEditor("editor1");
var editor2 = newChuckEditor("editor2");
editor2.setOptions({
  showLineNumbers: false
  , showGutter: false
});

var prependCode = `//  none needed
`;

var startButton = document.getElementById( "startButton" );
var startButtonWithInput = document.getElementById( "startButtonWithInput" );
var stopButton = document.getElementById( "stopButton" );
var recordButton = document.getElementById( "recordButton" );
stopButton.disabled = true;
startButton.style.height = '60px';
startButton.style.width= '120px';
startButtonWithInput.style.height = '60px';
startButtonWithInput.style.width= '120px';
stopButton.style.height = '60px';
stopButton.style.width= '120px';

startButton.addEventListener( "click", async function() {
  await prep(false);
  await theChuck.runCode(prependCode+editor1.getValue());
  stopButton.disabled = false;
  startButton.value = "Started";
  startButton.disabled = true;
  startButtonWithInput.disabled = true;
  startButton.style.background='White';  
  await new Promise(r => setTimeout(r, 100));
});

startButtonWithInput.addEventListener( "click", async function() {
  await prep(true);
  await theChuck.runCode(prependCode+editor1.getValue());
  stopButton.disabled = false;
  startButtonWithInput.value = "Started";
  startButtonWithInput.disabled = true;
  startButton.disabled = true;
  startButtonWithInput.style.background='White';  
  await new Promise(r => setTimeout(r, 100));
});

stopButton.addEventListener( "click", async function() {
  await theChuck.removeLastCode();
  disconnectAudioInput();
  stereoRecorder.stop();
  audioContext.suspend();
  if (recordButton.value == "Recording") createDownloadLink();
  recordButton.style.background='White';  
  recordButton.disabled = true;
});

recordButton.addEventListener( "click", async function() {
  record();
  recordButton.style.background='Coral';  
  recordButton.value = "Recording";
  stereoRecorder.start();
});

// mouse interface
var clickOn = true;
theChuckReady.then( function() {
  if( window.Event ) { 
    document.captureEvents( Event.MOUSEMOVE );
  }
  document.onmousemove = function( e )  {
      var x = (window.Event) ? e.pageX : event.clientX + (document.documentElement.scrollLeft ?     
        document.documentElement.scrollLeft : document.body.scrollLeft);
      var y = (window.Event) ? e.pageY : event.clientY + (document.documentElement.scrollTop ? 
        document.documentElement.scrollTop : document.body.scrollTop);
//      theChuck.setInt( "mouseX", x );
//      theChuck.setInt( "mouseY", y );
    }
  document.onmousedown = function( e )  {
        theChuck.broadcastEvent("playRiff");
  }
});
</script>
